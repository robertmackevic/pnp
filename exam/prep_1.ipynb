{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Intermediate Exam 2024 Solutions\n",
    "Robert Mackeviƒç"
   ],
   "id": "90b84a695b913c84"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-19T15:35:09.172183Z",
     "start_time": "2025-01-19T15:35:06.865926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Individualized parameters\n",
    "N = 6\n",
    "S = 8\n",
    "I1 = 5\n",
    "I2 = 4"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Problem 1",
   "id": "6e2912367c6a37ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Task (a)\n",
    "$N = 6 + 8 = 14$\\\n",
    "$q = 6 / (6 + 8) = 3/7 \\approx 0.4286$\\\n",
    "$j = 8$\n",
    "\n",
    "The quantile $y_{(q)}$ is defined as the $3/7$ of $Y$\\\n",
    "To locate the closest order statistic to $y_{(q)}$ we can calculate:\n",
    "$$q \\cdot N = 3/7 \\cdot 14 = 6$$\n",
    "So $y_{(q)}$ approximately represents $Y_{(6)}$\n",
    "\n",
    "We get this:\n",
    "$$P\\{Y_{(8)} \\leq y_{(q)} < Y_{(11)}\\}=0$$\n",
    "\n",
    "If $y_{(q)}$ approximately represents $Y_{(6)}$, then $Y_{(8)} \\leq y_{(q)}$ is impossible by the definition of order statistics."
   ],
   "id": "21e250bf70133f59"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Task (b)\n",
    "Original dataset size: $N = 2 + 6 = 8$\\\n",
    "New dataset size: $N = 4 + 6 = 8$\n",
    "\n",
    "- The mean of the dataset is affected significantly by the addition of extremes, as it is sensitive to outliers.\n",
    "- The median, remains unaffected by the addition of these extremes, as it is based on the ranks of the middle observations.\n",
    "- The range of the dataset increases, as the new observations extend the dataset in both directions.\n",
    "---\n"
   ],
   "id": "6c22ea3fda9c99f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Problem 2",
   "id": "51eaffd33a92aa1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Task (a)\n",
    "\n",
    "if $D \\leqslant Q$, then all demand is fulfilled: $pD$\\\n",
    "if $D > Q$, then only $Q$ kg is sold: $pQ$\\\n",
    "Cost is always $cQ$ single goods are acquired regardless of demand.\\\n",
    "$$\n",
    "G(Q) = p \\cdot \\mathbb{E}[\\min(D, Q)] - cQ\n",
    "$$\n",
    "$$\n",
    "G(Q) = p \\int_0^Q x \\, dF_D(x) + pQ \\int_Q^\\infty dF_D(x) - cQ\n",
    "$$\n",
    "$$\n",
    "G(Q) = p \\int_0^Q x \\, dF_D(x) + pQ \\cdot (1 - F_D(Q)) - cQ\n",
    "$$\n",
    "\n",
    "The optimal $Q^*$ maximizes $G(Q)$, which requires:\n",
    "$$\n",
    "\\frac{dG(Q)}{dQ} = 0\n",
    "$$\n",
    "Differentiating $G(Q)$:\n",
    "$$\n",
    "\\frac{dG(Q)}{dQ} = p \\cdot F_D(Q) - p \\cdot F_D(Q) + p \\cdot (1 - F_D(Q)) - c = 0\n",
    "$$\n",
    "$$\n",
    "p \\cdot (1 - F_D(Q)) - c = 0\n",
    "$$\n",
    "\n",
    "Solve for $Q^*$:\n",
    "$$\n",
    "F_D(Q^*) = 1 - \\frac{c}{p}\n",
    "$$\n",
    "$$\n",
    "Q^* = F_D^{-1}\\left(1 - \\frac{c}{p}\\right)\n",
    "$$"
   ],
   "id": "15d6e54242029d8d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Task (b)\n",
    "We can use EDF of $\\hat{F}_D(x)$ to estimate $G(Q)$\n",
    "$$\n",
    "\\hat{F}_D(x) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{1}_{\\{D_i \\leq x\\}}\n",
    "$$\n",
    "where $\\mathbb{1}_{\\{D_i \\leq x\\}}$ is the indicator function, which equals $1$ if $D_i \\leq x$ and $0$ otherwise.\n",
    "\n",
    "$$\n",
    "\\hat{G}(Q) = p \\sum_{i=1}^n \\frac{D_i \\cdot \\mathbb{1}_{\\{D_i \\leq Q\\}}}{n} + pQ \\cdot \\left[1 - \\frac{\\sum_{i=1}^n \\mathbb{1}_{\\{D_i \\leq Q\\}}}{n}\\right] - cQ\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{Q}^* = \\hat{F}_D^{-1}\\left(1 - \\frac{c}{p}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{G}(\\hat{Q}^*) = p \\sum_{i=1}^n \\frac{D_i \\cdot \\mathbb{1}_{\\{D_i \\leq \\hat{Q}^*\\}}}{n} + p \\hat{Q}^* \\cdot \\left[1 - \\frac{\\sum_{i=1}^n \\mathbb{1}_{\\{D_i \\leq \\hat{Q}^*\\}}}{n}\\right] - c \\hat{Q}^*\n",
    "$$"
   ],
   "id": "ab5a47db147aa1ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Task (c)\n",
    "$c = 8$\\\n",
    "$p = 6 + 8 = 14$\\\n",
    "$Q = 21 + 5 = 26$\\\n",
    "$D = \\{24,35,26,51,39,16,21,44,26\\}$\n",
    "\n",
    "Plug in the numbers into the equation from Task (b):\n",
    "$$ \\hat{G}(Q) = 129\\frac{5}{9} $$\n",
    "Find the smallest $Q^*$ such that $\\hat F_D(Q^*) \\geq 1-\\frac{c}{p}$:\n",
    "$$Q^*=26$$\n",
    "Repeat the calculations as in Step 1, using $Q^*$ instead of $Q$:\n",
    "$$ \\hat{G}(Q^*) = 129\\frac{5}{9} $$\n",
    "\n",
    "Solution is given in the below code block."
   ],
   "id": "9c566bd032b47a9d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T15:35:09.206534Z",
     "start_time": "2025-01-19T15:35:09.199535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "c = S\n",
    "p = N + S\n",
    "Q = 21 + I1\n",
    "\n",
    "data = np.array([19 + I1, 35, 26, 51, 39, 10 + N, 21, 44, 10 + 2 * S])\n",
    "n = len(data)\n",
    "\n",
    "\n",
    "def calculate_gain(Q):\n",
    "    indicator_leq_Q = (data <= Q).astype(int)\n",
    "    sum_D_leq_Q = np.sum(data * indicator_leq_Q)\n",
    "    sum_indicator_leq_Q = np.sum(indicator_leq_Q)\n",
    "    return p * (sum_D_leq_Q / n) + p * Q * (1 - (sum_indicator_leq_Q / n)) - c * Q\n",
    "\n",
    "\n",
    "hat_G_Q = calculate_gain(Q)\n",
    "\n",
    "F_hat_D = np.array([np.sum(data <= x) / n for x in sorted(data)])\n",
    "threshold = 1 - (c / p)\n",
    "Q_star_candidates = sorted(data)\n",
    "Q_star_index = np.argmax(F_hat_D >= threshold)\n",
    "Q_star = Q_star_candidates[Q_star_index]\n",
    "\n",
    "hat_G_Q_star = calculate_gain(Q_star)\n",
    "\n",
    "print(f\"Results:\")\n",
    "print(f\"G(Q) = {hat_G_Q:.4f}\")\n",
    "print(f\"Q* = {Q_star}\")\n",
    "print(f\"G(Q*) = {hat_G_Q_star:.4f}\")\n"
   ],
   "id": "3bb76929f1661cb2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "G(Q) = 129.5556\n",
      "Q* = 26\n",
      "G(Q*) = 129.5556\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Task (d)"
   ],
   "id": "2f0c99bace2943e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The variance of $\\hat{G}(Q)$ can be derived as:\n",
    "$$\n",
    "\\text{Var}(\\hat{G}(Q)) = p^2 \\cdot \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n D_i \\cdot \\mathbb{1}_{\\{D_i \\leq Q\\}}\\right) + p^2 Q^2 \\cdot \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n \\mathbb{1}_{\\{D_i \\leq Q\\}}\\right).\n",
    "$$\n",
    "\n",
    "1. **First Term**:\n",
    "   $$\n",
    "   \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n D_i \\cdot \\mathbb{1}_{\\{D_i \\leq Q\\}}\\right) = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(D_i \\cdot \\mathbb{1}_{\\{D_i \\leq Q\\}}),\n",
    "   $$\n",
    "    where:\n",
    "   $$\n",
    "   \\text{Var}(D_i \\cdot \\mathbb{1}_{\\{D_i \\leq Q\\}}) = \\mathbb{E}[(D_i \\cdot \\mathbb{1}_{\\{D_i \\leq Q\\}})^2] - (\\mathbb{E}[D_i \\cdot \\mathbb{1}_{\\{D_i \\leq Q\\}}])^2.\n",
    "   $$\n",
    "\n",
    "2. **Second Term**:\n",
    "\n",
    "   $$\n",
    "   \\text{Var}\\left(\\frac{1}{n} \\sum_{i=1}^n \\mathbb{1}_{\\{D_i \\leq Q\\}}\\right) = \\frac{1}{n^2} \\sum_{i=1}^n \\text{Var}(\\mathbb{1}_{\\{D_i \\leq Q\\}}),\n",
    "   $$\n",
    "\n",
    "   where:\n",
    "\n",
    "   $$\n",
    "   \\text{Var}(\\mathbb{1}_{\\{D_i \\leq Q\\}}) = \\mathbb{E}[\\mathbb{1}_{\\{D_i \\leq Q\\}}] \\cdot (1 - \\mathbb{E}[\\mathbb{1}_{\\{D_i \\leq Q\\}}]).\n",
    "   $$\n",
    "The variance of $\\hat{G}(\\hat{Q^*})$ follows the same form as $\\hat{G}(Q)$.\n",
    "\n",
    "Answer:\n",
    "$$\n",
    "\\text{Var}(\\hat{G}(Q)) = 6553.7668\n",
    "$$\n",
    "$$\n",
    "\\text{Var}(\\hat{G}(\\hat{Q^*})) = 6553.7668\n",
    "$$\n",
    "Solution is given in the below code block."
   ],
   "id": "969663581b98e66f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T15:35:09.350915Z",
     "start_time": "2025-01-19T15:35:09.346415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def variance_of_gain(Q):\n",
    "    indicator_leq_Q = (data <= Q).astype(int)\n",
    "    D_leq_Q = data * indicator_leq_Q\n",
    "\n",
    "    # First term variance\n",
    "    E_D_leq_Q = np.mean(D_leq_Q)\n",
    "    E_D_leq_Q_squared = np.mean(D_leq_Q ** 2)\n",
    "    var_D_leq_Q = E_D_leq_Q_squared - E_D_leq_Q ** 2\n",
    "\n",
    "    # Second term variance\n",
    "    E_indicator = np.mean(indicator_leq_Q)\n",
    "    var_indicator = E_indicator * (1 - E_indicator)\n",
    "\n",
    "    # Total variance\n",
    "    return (p ** 2 / n) * var_D_leq_Q + (p ** 2 * Q ** 2 / n) * var_indicator\n",
    "\n",
    "\n",
    "var_G_Q = variance_of_gain(Q)\n",
    "var_G_Q_star = variance_of_gain(Q_star)\n",
    "\n",
    "# Print results\n",
    "print(f\"Variance of G(Q): {var_G_Q:.4f}\")\n",
    "print(f\"Variance of G(Q*): {var_G_Q_star:.4f}\")"
   ],
   "id": "fe1495b6a0a2896c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of G(Q): 6553.7668\n",
      "Variance of G(Q*): 6553.7668\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Task (e)\n",
    "Robustness of $\\hat{G}(Q)$:\n",
    "- It is sensitive to outliers because it directly incorporates $D$ values in its computation. For instance, if most demands are around 20, but one is 100, it will heavily skew the gain calculation if $Q \\geq 100$.\n",
    "- With fewer data points it will become less reliable because the empirical distribution may poorly approximate the true distribution.\n",
    "\n",
    "Robustness of $\\hat{Q^*}$:\n",
    "- The optimal quantity depends on the quantile of the empirical distribution. Outliers can distort the EDF, shifting away from the true optimal value.\n",
    "- A small sample size can lead to incorrect estimates of the quantiles of EDF.\n",
    "\n",
    "Robustness of $\\hat{G}(\\hat{Q^*})$:\n",
    "- Combines the effects of outliers on both $\\hat{G}(Q)$ and $\\hat{Q^*}$.\n",
    "- Suffers from similar problems as the other estimators.\n",
    "---"
   ],
   "id": "f08081c908104749"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Problem 3",
   "id": "1538dfd7d1a9c694"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Task (a)\n",
    "From the context of the problem we can assume that $X$ and $Y$ follow binomial distributions:\n",
    "- There are $n$ independent trials.\n",
    "- Each trial results in a \"success\" (e.g., infection) or \"failure\" (e.g., no infection).\n",
    "- The probability of success, $p$, is the same for each trial.\n",
    "\n",
    "$X \\sim \\text{Binomial}(M, p_m)$ - $p_m$ infection rate for women.\\\n",
    "$Y \\sim \\text{Binomial}(N, p_n)$ - $p_n$ infection rate for men.\n",
    "\n",
    "The formula for $\\hat{\\rho}$ is:\n",
    "\n",
    "$$\n",
    "\\hat{\\rho} = \\frac{XN}{YM}.\n",
    "$$\n",
    "\n",
    "We rewrite it as a function of two variables:\n",
    "\n",
    "$$\n",
    "g(X, Y) = \\frac{XN}{YM}.\n",
    "$$\n",
    "\n",
    "The variance is approximated by:\n",
    "\n",
    "$$\n",
    "\\text{Var}(\\hat{\\rho}) \\approx \\left( \\frac{\\partial g}{\\partial X} \\right)^2 \\text{Var}(X) + \\left( \\frac{\\partial g}{\\partial Y} \\right)^2 \\text{Var}(Y),\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ \\frac{\\partial g}{\\partial X} = \\frac{N}{YM} $,\n",
    "- $ \\frac{\\partial g}{\\partial Y} = -\\frac{XN}{Y^2M} $.\n",
    "\n",
    "Substituting these derivatives:\n",
    "\n",
    "$$\n",
    "\\text{Var}(\\hat{\\rho}) \\approx \\left( \\frac{N}{YM} \\right)^2 \\text{Var}(X) + \\left( -\\frac{XN}{Y^2M} \\right)^2 \\text{Var}(Y).\n",
    "$$\n",
    "\n",
    "For binomial random variables:\n",
    "- $ \\text{Var}(X) = Mp_m(1 - p_m) $,\n",
    "- $ \\text{Var}(Y) = Np_n(1 - p_n) $.\n",
    "\n",
    "Substitute these variances:\n",
    "\n",
    "$$\n",
    "\\text{Var}(\\hat{\\rho}) \\approx \\left( \\frac{N}{YM} \\right)^2 \\cdot Mp_m(1 - p_m) + \\left( \\frac{XN}{Y^2M} \\right)^2 \\cdot Np_n(1 - p_n).\n",
    "$$\n",
    "\n",
    "The variance estimator for $ \\hat{\\rho} $ is:\n",
    "\n",
    "$$\n",
    "\\widehat{\\text{Var}}(\\hat{\\rho}) = \\left( \\frac{N}{YM} \\right)^2 \\cdot M\\hat{p}_m(1 - \\hat{p}_m) + \\left( \\frac{XN}{Y^2M} \\right)^2 \\cdot N\\hat{p}_n(1 - \\hat{p}_n),\n",
    "$$"
   ],
   "id": "2d9ec05528568665"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Task (b)\n",
    "- $H_0 : p_m = p_n$ - Infection rates for women and men are equal.\n",
    "- $H_1 : p_m \\ne p_n$ - Infection rates for women and men are not equal.\n",
    "\n",
    "The test statistic is:\n",
    "$$\n",
    "z = \\frac{\\hat{\\rho} - 1}{\\sqrt{\\widehat{\\text{Var}}(\\hat{\\rho})}},\n",
    "$$\n",
    "\n",
    "1. Determine the critical value for a two-tailed test at a significance level of 0.1:\n",
    "   $$\n",
    "   z_{\\alpha/2} = \\Phi^{-1}(1 - \\alpha/2) \\quad \\text{with } \\alpha = 0.1.\n",
    "   $$\n",
    "\n",
    "2. Reject $ H_0 $ if:\n",
    "   $$\n",
    "   |z| > z_{\\alpha/2}.\n",
    "   $$\n",
    "\n",
    "Otherwise, fail to reject $ H_0 $.\n",
    "\n",
    "\n",
    "The statistic $ \\frac{YM}{XN} $ is the reciprocal of $ \\hat{\\rho} $. While it could also be used to test $ H_0: p_m = p_n $, its interpretation flips because, if $ \\hat{\\rho} $ is large (e.g., $ p_m > p_n $), then $ \\frac{YM}{XN} $ will be small, and vice versa.\n",
    "For this specific test both will lead to the same decision.\n"
   ],
   "id": "938daae1f7a93a71"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "------\n",
    "#### Task (c)\n",
    "The estimator $\\hat\\rho$ is sensitive to extreme values because if $Y$ is very small or close to 0, then $\\hat\\rho$ becomes very large or undefined. Similarly, extreme values of $X$, $M$ or $N$ can distort the statistic as well.\n",
    "\n",
    "The maximal bias occurs when $\\hat\\rho$ deviates significantly from its expected value due to extreme changes in $Y$, $X$, $M$ or $N$.\n",
    "\n",
    "When:\\\n",
    "$X = 6$\\\n",
    "$M = 50 + 6 = 56$\\\n",
    "$Y = 8$\\\n",
    "$N = 100 + 8 = 108$\n",
    "\n",
    "$$\n",
    "\\hat{\\rho} = \\frac{6 \\cdot 108}{8 \\cdot 56} = \\frac{648}{448} \\approx 1.446.\n",
    "$$\n",
    "\n",
    "**Maximal Bias**\\\n",
    "Case 1: $ X $ is doubled $ X \\to 2X $\n",
    "$$\n",
    "\\hat{\\rho}_{\\text{bias}} = \\frac{12 \\cdot 108}{8 \\cdot 56} = \\frac{1284}{448} \\approx 2.868.\n",
    "$$\n",
    "Case 2: $ Y \\to Y/2 $\n",
    "$$\n",
    "\\hat{\\rho}_{\\text{bias}} = \\frac{6 \\cdot 108}{4 \\cdot 56} = \\frac{648}{224} \\approx 2.893.\n",
    "$$\n",
    "\n",
    "As $ Y \\to 0 : \\hat{\\rho} \\to \\infty $.\n",
    "\n",
    "**Break Point**\n",
    "   - $ X = 0 $: Contaminating $ \\frac{0}{56} = 0\\% $ (statistically irrelevant, but theoretically a break).\n",
    "   - $ Y = 0 $: Contaminating $ \\frac{8}{56} \\approx 14.3\\% $ of the data.\n",
    "\n",
    "---"
   ],
   "id": "a76d3ac2dc746631"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Problem 4",
   "id": "69ea30f81429f776"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Task (a)\n",
    "The parameter $\\alpha_2$ represents the variance of $X$, expressed as:\n",
    "$$\n",
    "\\alpha_2 = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2.\n",
    "$$\n",
    "\n",
    "The standard estimator for $\\alpha_2$ is:\n",
    "$$\n",
    "\\hat{\\alpha}_2 = S_2 - S_1^2,\n",
    "$$\n",
    "where:\n",
    "- $S_1 = \\frac{1}{n} \\sum_{j=1}^n X_j$: Sample mean,\n",
    "- $S_2 = \\frac{1}{n} \\sum_{j=1}^n X_j^2$: Mean of squared observations.\n",
    "\n",
    "The jackknife method estimates the bias by systematically removing one observation at a time. For each $i$-th observation, calculate:\n",
    "$$\n",
    "\\hat{\\alpha}_2^{(-i)} = S_2^{(-i)} - \\left(S_1^{(-i)}\\right)^2,\n",
    "$$\n",
    "where:\n",
    "- $S_1^{(-i)} = \\frac{1}{n-1} \\sum_{j \\neq i} X_j$: Mean without the $i$-th observation,\n",
    "- $S_2^{(-i)} = \\frac{1}{n-1} \\sum_{j \\neq i} X_j^2$: Mean of squares without the $i$-th observation.\n",
    "\n",
    "The bias-adjusted jackknife estimator is:\n",
    "$$\n",
    "\\hat{\\alpha}_2 = n \\cdot \\hat{\\alpha}_2 - (n-1) \\cdot \\bar{\\alpha}_2,\n",
    "$$\n",
    "where:\n",
    "- $\\hat{\\alpha}_2 = S_2 - S_1^2$: Original estimator,\n",
    "- $\\bar{\\alpha}_2 = \\frac{1}{n} \\sum_{i=1}^n \\hat{\\alpha}_2^{(-i)}$: Average of leave-one-out estimators.\n",
    "\n",
    "\n",
    "The variance of the jackknife estimator $\\hat{\\alpha}_2$ is:\n",
    "$$\n",
    "\\hat{V}^2 = \\frac{n-1}{n} \\sum_{i=1}^n \\left(\\hat{\\alpha}_2^{(-i)} - \\bar{\\alpha}_2\\right)^2,\n",
    "$$\n",
    "where:\n",
    "- $\\hat{\\alpha}_2^{(-i)} = S_2^{(-i)} - \\left(S_1^{(-i)}\\right)^2$: Leave-one-out estimators,\n",
    "- $\\bar{\\alpha}_2 = \\frac{1}{n} \\sum_{i=1}^n \\hat{\\alpha}_2^{(-i)}$: Mean of leave-one-out estimators.\n"
   ],
   "id": "52221c95a3ebc16b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Task (b)\n",
    "1. **Bias-Adjusted Estimator**:\n",
    "   - The jackknife bias correction works by averaging leave-one-out estimators $ \\hat{\\alpha}_2^{(-i)} $ and adjusting the original estimator $ \\hat{\\alpha}_2 $ to account for the bias.\n",
    "\n",
    "2. **Variance Estimator**:\n",
    "   - The variance $ \\hat{V}^2 $ reflects the variability of the leave-one-out estimators around their mean $ \\bar{\\alpha}_2 $, scaled for the sample size.\n",
    "\n",
    "3. **Assumptions**:\n",
    "   - Observations are i.i.d.,\n",
    "   - The second moment $ \\mathbb{E}[X^2] $ exists and is finite,\n",
    "   - The bias of $ \\hat{\\alpha}_2 $ is approximately constant."
   ],
   "id": "38447fb56cb260e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Task (c)"
   ],
   "id": "df7b9422ca989"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T15:35:09.450914Z",
     "start_time": "2025-01-19T15:35:09.445916Z"
    }
   },
   "cell_type": "code",
   "source": [
    "D = np.array([24, 35, 26, 51, 39, 16, 21, 44, 26])\n",
    "n = len(D)\n",
    "\n",
    "S1 = np.mean(D)\n",
    "S2 = np.mean(D ** 2)\n",
    "\n",
    "alpha_2 = S2 - S1 ** 2\n",
    "\n",
    "alpha_2_leave_one_out = []\n",
    "for i in range(n):\n",
    "    D_minus_i = np.delete(D, i)\n",
    "    S1_minus_i = np.mean(D_minus_i)\n",
    "    S2_minus_i = np.mean(D_minus_i ** 2)\n",
    "    alpha_2_leave_one_out.append(S2_minus_i - S1_minus_i ** 2)\n",
    "\n",
    "alpha_2_leave_one_out = np.array(alpha_2_leave_one_out)\n",
    "alpha_2_bar = np.mean(alpha_2_leave_one_out)\n",
    "\n",
    "alpha_2_jackknife = n * alpha_2 - (n - 1) * alpha_2_bar\n",
    "\n",
    "V2 = (n - 1) / n * np.sum((alpha_2_leave_one_out - alpha_2_bar) ** 2)\n",
    "\n",
    "print(f\"Standard alpha_2 estimator: {alpha_2:.4f}\")\n",
    "print(f\"Bias-adjusted alpha_2 (jackknife): {alpha_2_jackknife:.4f}\")\n",
    "print(f\"Variance of alpha_2 (jackknife): {V2:.4f}\")"
   ],
   "id": "5255a82809df23b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard alpha_2 estimator: 119.1111\n",
      "Bias-adjusted alpha_2 (jackknife): 134.0000\n",
      "Variance of alpha_2 (jackknife): 2152.9141\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "c8e3e93585d5585a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Problem 5",
   "id": "a9575894b9c18974"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Task (1)\n",
    "**Step 1: Define the Test Statistic**\n",
    "\n",
    "- For the mean: Use the sample mean $\\bar{Y}$:\n",
    "  $$\n",
    "  T(Y) = \\bar{Y}\n",
    "  $$\n",
    "\n",
    "- **For the median**: Use the sample median $\\text{med}(Y)$:\n",
    "  $$\n",
    "  T(Y) = \\text{med}(Y)\n",
    "  $$\n",
    "\n",
    "Under $H_0$, $T(Y)$ should be close to $N$.\n",
    "\n",
    "**Step 2: Compute the Observed Test Statistic**\n",
    "\n",
    "Compute the observed test statistic $T_{\\text{obs}}$ from the given data:\n",
    "\n",
    "$$\n",
    "T_{\\text{obs}} =\n",
    "\\begin{cases}\n",
    "\\bar{Y} & \\text{for the mean} \\\\\n",
    "\\text{med}(Y) & \\text{for the median}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Step 3: Generate Bootstrap Samples**\n",
    "\n",
    "Resample the observed data $Y_1, Y_2, \\dots, Y_n$ with replacement to generate bootstrap samples $Y_1^*, Y_2^*, \\dots, Y_n^*$.\n",
    "\n",
    "For each bootstrap sample $Y^*$, compute the test statistic $T(Y^*)$:\n",
    "\n",
    "$$\n",
    "T^* =\n",
    "\\begin{cases}\n",
    "\\bar{Y}^* & \\text{for the mean} \\\\\n",
    "\\text{med}(Y^*) & \\text{for the median}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Repeat this $B$ times (e.g., $B = 1000$) to generate a bootstrap distribution of $T^*$.\n",
    "\n",
    "**Step 4: Compute the $p$-Value**\n",
    "\n",
    "Calculate the $p$-value as the proportion of bootstrap statistics $T^*$ that are at least as extreme as $T_{\\text{obs}}$ under $H_0$:\n",
    "\n",
    "$$\n",
    "p = \\frac{\\# \\left\\{ T^* : \\left| T^* - N \\right| \\geq \\left| T_{\\text{obs}} - N \\right| \\right\\}}{B}\n",
    "$$\n",
    "\n",
    "**Step 5: Decision Rule**\n",
    "\n",
    "If $p \\leq \\alpha$ (e.g., $\\alpha = 0.1$), reject $H_0$: The mean or median significantly differs from $N$.\n",
    "\n",
    "Otherwise, fail to reject $H_0$: No significant evidence to conclude $\\mu(F_Y) \\neq N$."
   ],
   "id": "db14992eaf33b51f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Task (2)\n",
    "**Step 1: Define the Test Statistic**\n",
    "\n",
    "- **For the mean**: Use the transformed data $h(Y)$ to compute the sample mean:\n",
    "\n",
    "$$\n",
    "T(Y) = \\bar{h(Y)} = \\frac{1}{n} \\sum_{j=1}^{n} h(Y_j)\n",
    "$$\n",
    "\n",
    "- **For the median**: Use the transformed data $h(Y)$ to compute the sample median:\n",
    "\n",
    "$$\n",
    "T(Y) = \\text{med}(h(Y))\n",
    "$$\n",
    "\n",
    "Under $H_0$, the symmetry of $h(Y)$ about $a$ ensures that $T(Y)$ reflects the central tendency of $h(Y)$, and its expected value aligns with $N$.\n",
    "\n",
    "**Step 2: Compute the Observed Test Statistic**\n",
    "\n",
    "Transform the data $h(Y)$ using the known function $h$. Compute the observed test statistic $T_{\\text{obs}}$:\n",
    "\n",
    "$$\n",
    "T_{\\text{obs}} =\n",
    "\\begin{cases}\n",
    "\\bar{h(Y)} & \\text{for the mean} \\\\\n",
    "\\text{med}(h(Y)) & \\text{for the median}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**Step 3: Center the Transformed Data**\n",
    "\n",
    "Center the transformed data $h(Y)$ around its observed central tendency:\n",
    "\n",
    "$$\n",
    "h(Y)_{\\text{centered}} = h(Y) - T_{\\text{obs}} + N\n",
    "$$\n",
    "\n",
    "where $N$ is the hypothesized mean/median under $H_0$.\n",
    "\n",
    "Resample $h(Y)_{\\text{centered}}$ with replacement to generate bootstrap samples:\n",
    "\n",
    "$$\n",
    "h(Y)_{\\text{centered}}^*\n",
    "$$\n",
    "\n",
    "For each bootstrap sample, compute the test statistic $T^*$:\n",
    "\n",
    "$$\n",
    "T^* =\n",
    "\\begin{cases}\n",
    "\\bar{h(Y)}^* & \\text{for the mean} \\\\\n",
    "\\text{med}(h(Y)^*) & \\text{for the median}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Repeat this $B$ times (e.g., $B = 1000$) to generate a bootstrap distribution of $T^*$.\n",
    "\n",
    "**Step 4: Compute the $p$-Value**\n",
    "\n",
    "Calculate the $p$-value as the proportion of bootstrap statistics $T^*$ that are at least as extreme as $T_{\\text{obs}}$ under $H_0$:\n",
    "\n",
    "$$\n",
    "p = \\frac{\\# \\left\\{ T^* : \\left| T^* - N \\right| \\geq \\left| T_{\\text{obs}} - N \\right| \\right\\}}{B}\n",
    "$$\n",
    "\n",
    "**Step 5: Decision Rule**\n",
    "\n",
    "If $p \\leq \\alpha$ (e.g., $\\alpha = 0.1$), reject $H_0$: The mean or median significantly differs from $N$.\n",
    "\n",
    "Otherwise, fail to reject $H_0$: No significant evidence to conclude $\\mu(F_Y) \\neq N$.\n",
    "\n",
    "---"
   ],
   "id": "20eff94a0112fa19"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Problem 6",
   "id": "71b312d0358b2f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Task (a)\n",
    "Need to estimate the unknown label of the element $\\omega^\\circ$, which is drawn from one of two classes: $\\Omega_1$ or $\\Omega_2$.\n",
    "$Y^\\circ = 6 - \\frac{8}{2} = 6 - 4 = 2$\\\n",
    "$b = 3 + N = 3 + 6 = 9$\\\n",
    "$p_1 = \\frac{6}{6 + 8} = \\frac{6}{14} \\approx 0.4286$\n",
    "$$\n",
    "f_1(u) = \\frac{1}{9} \\left( 1 - \\frac{|u|}{9} \\right) \\cdot 1\\{ |u| < 9 \\}\n",
    "$$\n",
    "\n",
    "A training sample $T = \\{ Y_t \\}_{t=1}^{20}$ is available for $\\Omega_2$, and the differences for 16 of the closest observations to $Y^\\circ$ are given as:\n",
    "\n",
    "$$\n",
    "\\{-0.8, -1.1, -2.8, 3.4, -4.2, -2.7, 1.9, 2.9, -3.7, 2.0, 0.4, -1.4, 4.9, 5.7, -3.3, -4.4\\}\n",
    "$$"
   ],
   "id": "c9bc3cd16658d5fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T15:35:09.530362Z",
     "start_time": "2025-01-19T15:35:09.521860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Y_circ = N - S / 2\n",
    "b = 3 + N\n",
    "p1 = N / (N + S)\n",
    "p2 = 1 - p1\n",
    "\n",
    "differences = np.array([\n",
    "    -I2 / 5, -1.1, -2.8, 3.4, -4.2, -2.7, 1.9, 2.9, -3.7, 2.0, 0.4, -1.4, 4.9, 5.7, -3.3, -4.4\n",
    "])\n",
    "\n",
    "if abs(Y_circ) < b:\n",
    "    f1_Y_circ = (1 / b) * (1 - abs(Y_circ) / b)\n",
    "else:\n",
    "    f1_Y_circ = 0\n",
    "\n",
    "kde = gaussian_kde(differences)\n",
    "f2_Y_circ = kde(Y_circ)\n",
    "\n",
    "numerator_1 = p1 * f1_Y_circ\n",
    "numerator_2 = p2 * f2_Y_circ\n",
    "denominator = numerator_1 + numerator_2\n",
    "\n",
    "P_Omega_1 = numerator_1 / denominator\n",
    "P_Omega_2 = numerator_2 / denominator\n",
    "\n",
    "classification = \"Omega_1\" if P_Omega_1 > P_Omega_2 else \"Omega_2\"\n",
    "\n",
    "print(\"Classification Results:\")\n",
    "print(f\"f1(Y^circ): {f1_Y_circ:.5f}\")\n",
    "print(f\"f2(Y^circ): {f2_Y_circ.item():.5f}\")\n",
    "print(f\"P(Omega_1 | Y^circ): {P_Omega_1.item():.5f}\")\n",
    "print(f\"P(Omega_2 | Y^circ): {P_Omega_2.item():.5f}\")\n",
    "print(f\"Classification: {classification}\")"
   ],
   "id": "4c1c3e481e105d7a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Results:\n",
      "f1(Y^circ): 0.08642\n",
      "f2(Y^circ): 0.07545\n",
      "P(Omega_1 | Y^circ): 0.46207\n",
      "P(Omega_2 | Y^circ): 0.53793\n",
      "Classification: Omega_2\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **$P(\\Omega_1 \\mid Y^\\circ)$** = 0.46207: The probability that $\\omega^\\circ$ belongs to class $\\Omega_1$ given $Y^\\circ$.\n",
    "- **$P(\\Omega_2 \\mid Y^\\circ)$** = 0.53793: The probability that $\\omega^\\circ$ belongs to class $\\Omega_2$ given $Y^\\circ$.\n",
    "\n",
    "Based on the posterior probabilities:\n",
    "\n",
    "$$\n",
    "P(\\Omega_2 \\mid Y^\\circ) > P(\\Omega_1 \\mid Y^\\circ)\n",
    "$$\n",
    "\n",
    "Since $P(\\Omega_2 \\mid Y^\\circ) > P(\\Omega_1 \\mid Y^\\circ)$, $\\omega^\\circ$ is classified into class $\\Omega_2$."
   ],
   "id": "48aa304118ed9b7b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "---\n",
    "#### Task (b)\n",
    "The Epanechnikov kernel for $f_2$ is:\n",
    "$$\n",
    "K(u) = \\frac{3}{4b} \\left( 1 - \\left( \\frac{u}{b} \\right)^2 \\right) \\cdot 1\\{ |u| < b \\}\n",
    "$$\n",
    "\n",
    "where $b = 3 + N = 9$.\n",
    "\n",
    "Using the given training sample $T$ for $\\Omega_2$, the kernel estimate $\\hat{f}_2(Y^\\circ)$ is computed as:\n",
    "\n",
    "$$\n",
    "\\hat{f}_2(Y^\\circ) = \\frac{1}{n} \\sum_{i=1}^{n} K\\left( \\frac{Y^\\circ - Y_i}{b} \\right)\n",
    "$$\n",
    "\n",
    "where $Y_i$ are the training observations for $\\Omega_2$."
   ],
   "id": "41c0f5e7652ad52e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T15:35:09.571363Z",
     "start_time": "2025-01-19T15:35:09.560865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def epanechnikov_kernel(u, b):\n",
    "    return (3 / (4 * b)) * (1 - (u / b) ** 2) * (np.abs(u) < b)\n",
    "\n",
    "\n",
    "f2_Y_circ_kernel = np.mean([epanechnikov_kernel((Y_circ - y_i), b) for y_i in differences])\n",
    "\n",
    "if abs(Y_circ) < b:\n",
    "    f1_Y_circ = (1 / b) * (1 - abs(Y_circ) / b)\n",
    "else:\n",
    "    f1_Y_circ = 0\n",
    "\n",
    "numerator_1 = p1 * f1_Y_circ\n",
    "numerator_2 = p2 * f2_Y_circ_kernel\n",
    "denominator = numerator_1 + numerator_2\n",
    "\n",
    "P_Omega_1 = numerator_1 / denominator\n",
    "P_Omega_2 = numerator_2 / denominator\n",
    "\n",
    "classification = \"Omega_1\" if P_Omega_1 > P_Omega_2 else \"Omega_2\"\n",
    "\n",
    "print(\"Kernel Classification Results:\")\n",
    "print(f\"f1(Y^circ): {f1_Y_circ:.5f}\")\n",
    "print(f\"Kernel Estimate of f2(Y^circ): {f2_Y_circ_kernel:.5f}\")\n",
    "print(f\"P(Omega_1 | Y^circ): {P_Omega_1:.5f}\")\n",
    "print(f\"P(Omega_2 | Y^circ): {P_Omega_2:.5f}\")\n",
    "print(f\"Classification: {classification}\")"
   ],
   "id": "1e266103cb0b664e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Classification Results:\n",
      "f1(Y^circ): 0.08642\n",
      "Kernel Estimate of f2(Y^circ): 0.06780\n",
      "P(Omega_1 | Y^circ): 0.48874\n",
      "P(Omega_2 | Y^circ): 0.51126\n",
      "Classification: Omega_2\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- **$P(\\Omega_1 \\mid Y^\\circ)$** = 0.48874: The probability that $\\omega^\\circ$ belongs to class $\\Omega_1$, considering the prior probability and class density $f_1$.\n",
    "- **$P(\\Omega_2 \\mid Y^\\circ)$** = 0.51126: The probability that $\\omega^\\circ$ belongs to class $\\Omega_2$, considering the prior probability and kernel-estimated class density $f_2$.\n",
    "\n",
    "Since:\n",
    "\n",
    "$$\n",
    "P(\\Omega_2 \\mid Y^\\circ) > P(\\Omega_1 \\mid Y^\\circ)\n",
    "$$\n",
    "\n",
    "The element $\\omega^\\circ$ is classified into class $\\Omega_2$.\n",
    "\n",
    "---"
   ],
   "id": "eef98f72293108d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
