{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e368651e76113e74",
   "metadata": {},
   "source": [
    "## Intermediate Exam 2022 Solutions\n",
    "**Robert Mackevič**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de714a445e1ef19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:15:41.442887Z",
     "start_time": "2025-01-19T19:15:39.662045Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Individualized parameters\n",
    "N = 6\n",
    "S = 8\n",
    "I1 = 5\n",
    "I2 = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e68ba4c68eb8d",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bead1d1b77c9ae86",
   "metadata": {},
   "source": [
    "#### Task (a)\n",
    "$$\n",
    "q_1 = \\frac{1 + 6 + 8}{6} = \\frac{15}{6} = 0.4\n",
    "$$\n",
    "$$\n",
    "q_2 = \\frac{1 + 6 + 8}{6 + 8} = \\frac{15}{14} \\approx 0.9333\n",
    "$$\n",
    "\n",
    "**$P\\{Y > y(q_1)\\}$** is the probability that $Y$ exceeds the 40th percentile, which corresponds to:\n",
    "\n",
    "$$\n",
    "P\\{Y > y(q_1)\\} = 1 - F_Y(y(q_1)) = 1 - 0.4 = 0.6\n",
    "$$\n",
    "\n",
    "**$P\\{y(q_1) < Y \\leq y(q_2)\\}$** is the probability that $Y$ falls between the 40th and approximately 93.33rd percentiles:\n",
    "\n",
    "$$\n",
    "P\\{y(q_1) < Y \\leq y(q_2)\\} = F_Y(y(q_2)) - F_Y(y(q_1)) = 0.9333 - 0.4 = 0.5333\n",
    "$$\n",
    "\n",
    "Assumptions:\n",
    "- $Y$ follows a continuous distribution $F_Y$ such that the quantiles $y(q_1)$ and $y(q_2)$ exist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b71a16a990f2816",
   "metadata": {},
   "source": [
    "----\n",
    "#### Task (b)\n",
    "- **$N$**: The total number of observations is:\n",
    "$$\n",
    "N = 3 + 6 + 8 = 17\n",
    "$$\n",
    "- **$m_1$** denotes the 6th order statistic:\n",
    "$$\n",
    "m_1 = 6\n",
    "$$\n",
    "\n",
    "- **$m_2$**: denotes 14th order statistic:\n",
    "$$\n",
    "m_2 = 6 + 8 = 14\n",
    "$$\n",
    "\n",
    "- **$N_1$** counts the number of observations greater than the 6th order statistic $Y(m_1)$. It represents the 11 largest values (17 total values minus the first 6 smallest):\n",
    "\n",
    "$$\n",
    "N_1 = \\#\\{ t \\in [1, 17] : Y_t > Y(6) \\} = 11\n",
    "$$\n",
    "\n",
    "- **$N_2$** counts the number of observations between the 6th order statistic $Y(m_1)$ and the 14th order statistic $Y(m_2)$. It represents the 8 values between the 6th and 14th smallest:\n",
    "\n",
    "$$\n",
    "N_2 = \\#\\{ t \\in [1, 17] : Y(6) < Y_t \\leq Y(14) \\} = 8\n",
    "$$\n",
    "\n",
    "Assumptions:\n",
    "1. The data $Y_t$ are independent and identically distributed (i.i.d.).\n",
    "2. The values $Y_t$ are continuous, ensuring no ties among the order statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f11f0243a1fb23c",
   "metadata": {},
   "source": [
    "----\n",
    "#### Task (c)\n",
    "$$\n",
    "N = 1 + 6 = 7\n",
    "$$\n",
    "$$\n",
    "m = 7\n",
    "$$\n",
    "$$\n",
    "q = \\frac{S}{N + S} = \\frac{8}{7 + 8} = \\frac{8}{15} \\approx 0.5333\n",
    "$$\n",
    "\n",
    "- $Y(m)$ is the 7th order statistic, which is the largest observation since $m = N = 7$.\n",
    "- $y(q)$ is the 53.33rd percentile of the distribution $F_Y$.\n",
    "\n",
    "The probability $P\\{Y(m) \\leq y(q)\\}$ is the probability that all $N = 7$ observations are less than or equal to $y(q)$. For independent and identically distributed (i.i.d.) observations, this can be written as:\n",
    "\n",
    "$$\n",
    "P\\{Y(m) \\leq y(q)\\} = P\\{Y_1 \\leq y(q)\\}^N = F_Y(y(q))^N\n",
    "$$\n",
    "\n",
    "Substituting the values:\n",
    "\n",
    "$$\n",
    "P\\{Y(m) \\leq y(q)\\} = F_Y(y(q))^7\n",
    "$$\n",
    "\n",
    "At $q = 0.5333$, we have:\n",
    "\n",
    "$$\n",
    "F_Y(y(q)) = q = 0.5333\n",
    "$$\n",
    "\n",
    "Thus, the probability becomes:\n",
    "\n",
    "$$\n",
    "P\\{Y(m) \\leq y(q)\\} = (0.5333)^7 \\approx 0.01227\n",
    "$$\n",
    "\n",
    "Assumptions\n",
    "\n",
    "1. The sample $Y_t$ is i.i.d. from the distribution $F_Y$.\n",
    "2. The distribution $F_Y$ is continuous, ensuring well-defined order statistics and quantiles.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dd760d79368a81",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1a0eac09017ba",
   "metadata": {},
   "source": [
    "#### Task (a)\n",
    "**L-statistics Example: Sample Median**\n",
    "\n",
    "- **Statistic**: Median\n",
    "- **Definition**: The median is a special case of an L-statistic:\n",
    "\n",
    "$$\n",
    "\\text{Median} = Y(m), \\quad m = \\lceil \\frac{N}{2} \\rceil\n",
    "$$\n",
    "\n",
    "where $Y(m)$ is the middle value in the ordered sample.\n",
    "\n",
    "- **Parameter Estimated**: The median is an estimator of the 50th percentile (or 0.5-quantile) of the distribution $F_Y$.\n",
    "\n",
    "- **Explanation**: The median is robust to outliers and provides a measure of central tendency, especially for skewed distributions.\n",
    "\n",
    "**R-statistics Example: Spearman's Rank Correlation**\n",
    "\n",
    "- **Statistic**: Spearman's $\\rho$\n",
    "- **Definition**: Spearman's rank correlation measures the association between two variables by comparing their rank statistics:\n",
    "\n",
    "$$\n",
    "\\rho = 1 - \\frac{6 \\sum_{t=1}^{N} (R(X_t) - R(Y_t))^2}{N(N^2 - 1)}\n",
    "$$\n",
    "\n",
    "where $R(X_t)$ and $R(Y_t)$ are the ranks of the values $X_t$ and $Y_t$.\n",
    "\n",
    "- **Parameter Estimated**: A measure of monotonic relationship between two variables.\n",
    "\n",
    "- **Explanation**: It uses ranks to determine correlation, making it robust to nonlinear relationships and outliers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd1e4e5945e40b0",
   "metadata": {},
   "source": [
    "---\n",
    "#### Task (b)\n",
    "**1. Estimating $a$ (Location Parameter) when $b = 1$**\n",
    "\n",
    "**L-statistics Construction**\n",
    "\n",
    "- **Statistic**: Sample Median\n",
    "- **Definition**: The sample median is given by:\n",
    "\n",
    "$$\n",
    "\\text{Median} = Y(m), \\quad \\text{where } m = \\lceil N/2 \\rceil\n",
    "$$\n",
    "\n",
    "The sample median is an L-statistic:\n",
    "\n",
    "$$\n",
    "L_N = \\sum_{t=1}^{N} c_t Y(t)\n",
    "$$\n",
    "\n",
    "where $c_t = 1$ for $t = m$ and $c_t = 0$ otherwise.\n",
    "\n",
    "- **Parameter Estimated**: The median is a robust estimator of $a$, assuming $F^\\circ$ is symmetric around $a$.\n",
    "\n",
    "- **Explanation**: The median minimizes the sum of absolute deviations, making it robust to outliers in the data $Y_t$.\n",
    "\n",
    "**R-statistics Construction**\n",
    "\n",
    "- **Statistic**: Hodges-Lehmann Estimator\n",
    "- **Definition**: The Hodges-Lehmann estimator for $a$ is:\n",
    "\n",
    "$$\n",
    "R_N = \\text{Median}\\left( \\frac{Y_i + Y_j}{2} : 1 \\leq i < j \\leq N \\right)\n",
    "$$\n",
    "\n",
    "- **Parameter Estimated**: The location parameter $a$.\n",
    "\n",
    "- **Explanation**: By averaging all pairs of values, the estimator remains robust while efficiently using rank-based information.\n",
    "\n",
    "**2. Estimating $b$ (Scale Parameter) when $a = 0$**\n",
    "\n",
    "**L-statistics Construction**\n",
    "\n",
    "- **Statistic**: Interquartile Range (IQR)\n",
    "- **Definition**: The IQR is the difference between the 75th and 25th percentiles:\n",
    "\n",
    "$$\n",
    "\\text{IQR} = Y(q_3) - Y(q_1)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $q_3 = \\lceil 0.75N \\rceil$\n",
    "- $q_1 = \\lceil 0.25N \\rceil$\n",
    "\n",
    "The L-statistic for the IQR is:\n",
    "\n",
    "$$\n",
    "L_N = \\sum_{t=1}^{N} c_t Y(t)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $c_{q_1} = -1$\n",
    "- $c_{q_3} = 1$\n",
    "- $c_t = 0$ otherwise.\n",
    "\n",
    "- **Parameter Estimated**: $b$, assuming $F^\\circ$ is symmetric and normalized.\n",
    "\n",
    "- **Explanation**: The IQR scales linearly with the spread of the data and is robust to outliers.\n",
    "\n",
    "**R-statistics Construction**\n",
    "\n",
    "- **Statistic**: Gini's Mean Difference\n",
    "- **Definition**: Gini's mean difference is defined as:\n",
    "\n",
    "$$\n",
    "R_N = \\frac{1}{N(N-1)} \\sum_{i=1}^{N} \\sum_{j=1}^{N} |Y_i - Y_j|\n",
    "$$\n",
    "\n",
    "- **Parameter Estimated**: $b$, as it measures dispersion.\n",
    "\n",
    "- **Explanation**: It uses rank-based pairwise differences to provide a robust estimate of scale.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b88ed65aecdaeb",
   "metadata": {},
   "source": [
    "---\n",
    "#### Task (c)\n",
    "$$\n",
    "N = 2(8) + 6 = 16 + 6 = 22\n",
    "$$\n",
    "\n",
    "The L-statistic uses the range of order statistics from $Y(S)$ to $Y(N - m)$. The effective size is:\n",
    "\n",
    "$$\n",
    "\\text{Effective Size} = (22 - 10) - 8 + 1 = 12 - 8 + 1 = 5\n",
    "$$\n",
    "\n",
    "The L-statistic ignores:\n",
    "\n",
    "- The smallest $7$ values.\n",
    "- The largest $m = 10$ values.\n",
    "\n",
    "$$\n",
    "\\text{Ignored Size} = 7 + 10 = 17\n",
    "$$\n",
    "\n",
    "The proportion of ignored data is:\n",
    "\n",
    "$$\n",
    "\\text{Proportion Ignored} = \\frac{\\text{Ignored Size}}{\\text{Total Size}} = \\frac{17}{22}\n",
    "$$\n",
    "The breakout point is:\n",
    "$$\n",
    "\\text{Breakout Point} = \\frac{17}{22} \\approx 0.7727\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af756ac82311c554",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "390b09f5588f5e49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:13:47.902311Z",
     "start_time": "2025-01-19T19:13:47.891270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repayments for each consumer: [1000.   357.5  183.6  430.  3000.   412.5]\n",
      "Expected repayment for one consumer: 897.27\n",
      "Variance of repayment for one consumer: 947674.44\n",
      "Expected total repayment for 100 consumers: 89726.67\n",
      "Variance of total repayment for 100 consumers: 94767443.89\n"
     ]
    }
   ],
   "source": [
    "r = N / (20 * S)\n",
    "tau = 21 + I1\n",
    "\n",
    "loan_data = [\n",
    "    (1000, 18),\n",
    "    (200, 47),\n",
    "    (50 + I2, 90),\n",
    "    (400, 20 + S),\n",
    "    (3000, 7),\n",
    "    (300, 36),\n",
    "]\n",
    "\n",
    "repayments = []\n",
    "for S_i, T_i in loan_data:\n",
    "    repayment = S_i + S_i * r * max(0, T_i - tau)\n",
    "    repayments.append(repayment)\n",
    "\n",
    "repayments = np.array(repayments)\n",
    "\n",
    "mean_repayment = repayments.mean()\n",
    "var_single_repayment = np.var(repayments, ddof=0)\n",
    "\n",
    "expected_total_repayment = 100 * mean_repayment\n",
    "var_total_repayment = 100 * var_single_repayment\n",
    "\n",
    "print(f\"Repayments for each consumer: {repayments}\")\n",
    "print(f\"Expected repayment for one consumer: {mean_repayment:.2f}\")\n",
    "print(f\"Variance of repayment for one consumer: {var_single_repayment:.2f}\")\n",
    "print(f\"Expected total repayment for 100 consumers: {expected_total_repayment:.2f}\")\n",
    "print(f\"Variance of total repayment for 100 consumers: {var_total_repayment:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58624c87d96ef80",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554132d5d2168f87",
   "metadata": {},
   "source": [
    "### Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20fe8389406fc81c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:16:42.873794Z",
     "start_time": "2025-01-19T19:16:42.863224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success rate (r): 0.2000\n",
      "Total trials: 60\n",
      "Estimated probability of success (p^): 0.2000\n",
      "Logit function value (θ): -1.3863\n",
      "Variance of logit function estimator: 1.0417e-01\n",
      "90% Lower one-sided confidence interval for θ: (-1.7999, ∞)\n"
     ]
    }
   ],
   "source": [
    "r = S / 40\n",
    "trials = N * 10\n",
    "\n",
    "# Observed successes (assume successes observed = r * trials)\n",
    "successes = r * trials\n",
    "\n",
    "# Estimate probability of success\n",
    "p_hat = successes / trials\n",
    "\n",
    "# Logit function\n",
    "logit_theta = np.log(p_hat / (1 - p_hat))\n",
    "\n",
    "# Variance of the logit estimator using the delta method\n",
    "variance_logit = (1 / (p_hat * (1 - p_hat) * trials))\n",
    "\n",
    "# 90% lower one-sided confidence interval for the logit function\n",
    "z_score = norm.ppf(0.90)  # Z-score for 90% confidence\n",
    "lower_bound = logit_theta - z_score * np.sqrt(variance_logit)\n",
    "\n",
    "print(f\"Success rate (r): {r:.4f}\")\n",
    "print(f\"Total trials: {trials}\")\n",
    "print(f\"Estimated probability of success (p^): {p_hat:.4f}\")\n",
    "print(f\"Logit function value (\\u03B8): {logit_theta:.4f}\")\n",
    "print(f\"Variance of logit function estimator: {variance_logit:.4e}\")\n",
    "print(f\"90% Lower one-sided confidence interval for \\u03B8: ({lower_bound:.4f}, \\u221E)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa32bf7367b7d9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5086c87b1d828b",
   "metadata": {},
   "source": [
    "### Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b1b71506f02926",
   "metadata": {},
   "source": [
    "#### Task (a)\n",
    "The bias of $\\hat{\\sigma}_N^2$ is the expected difference between $\\hat{\\sigma}_N^2$ and the true variance $\\sigma^2$:\n",
    "\n",
    "$$\n",
    "\\text{Bias}[\\hat{\\sigma}_N^2] = E[\\hat{\\sigma}_N^2] - \\sigma^2\n",
    "$$\n",
    "\n",
    "For a sample of size $N$, the sample variance $\\hat{\\sigma}_N^2$ is an unbiased estimator:\n",
    "\n",
    "$$\n",
    "E[\\hat{\\sigma}_N^2] = \\sigma^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Bias}[\\hat{\\sigma}_N^2] = 0\n",
    "$$\n",
    "\n",
    "The variance of $\\hat{\\sigma}_N^2$ measures the spread of $\\hat{\\sigma}_N^2$ around its mean:\n",
    "\n",
    "$$\n",
    "\\text{Var}[\\hat{\\sigma}_N^2] = E[(\\hat{\\sigma}_N^2 - \\sigma^2)^2]\n",
    "$$\n",
    "\n",
    "For small sample sizes, an approximation for the variance is:\n",
    "\n",
    "$$\n",
    "\\text{Var}[\\hat{\\sigma}_N^2] \\approx \\frac{2\\sigma^4}{N - 1}\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$\n",
    "\\sigma^4 = E[(Y - \\mu)^4]\n",
    "$$\n",
    "\n",
    "and $\\mu = E[Y]$.\n",
    "\n",
    "The bias of $\\hat{\\sigma}_N$ is more complex due to the square root operation:\n",
    "\n",
    "$$\n",
    "\\text{Bias}[\\hat{\\sigma}_N] = E[\\hat{\\sigma}_N] - \\sigma\n",
    "$$\n",
    "\n",
    "Using a Taylor expansion, an approximation for the bias of $\\hat{\\sigma}_N$ is:\n",
    "\n",
    "$$\n",
    "\\text{Bias}[\\hat{\\sigma}_N] \\approx -\\frac{\\sigma^2}{2N}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0dfda3da2adcdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:25:08.198073Z",
     "start_time": "2025-01-19T19:25:08.189303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: [6, 0, 8]\n",
      "Sample mean: 4.6667\n",
      "Sample variance (σ̂²_N): 11.5556\n",
      "Bias of σ̂²_N: 5.7778\n",
      "Variance of σ̂²_N: 100.1481\n",
      "Sample standard deviation (σ̂_N): 3.3993\n",
      "Bias of σ̂_N: 2.4037\n",
      "Variance of σ̂_N: 14.7305\n"
     ]
    }
   ],
   "source": [
    "sample = [N, 0, S]\n",
    "n = len(sample)\n",
    "\n",
    "# Calculate sample variance σ̂²_N\n",
    "sample_mean = np.mean(sample)\n",
    "sample_variance = np.mean((np.array(sample) - sample_mean)**2)\n",
    "\n",
    "# Bias of σ̂²_N (nonparametric bias estimator)\n",
    "bias_variance = (1 / n) * np.var(sample, ddof=1)\n",
    "\n",
    "# Variance of σ̂²_N (nonparametric variance estimator)\n",
    "variance_variance = (2 / (n * (n - 1))) * np.var(sample, ddof=1)**2\n",
    "\n",
    "# Standard deviation estimator σ̂_N\n",
    "sample_std_dev = np.sqrt(sample_variance)\n",
    "\n",
    "# Bias of σ̂_N\n",
    "bias_std_dev = np.sqrt(bias_variance)\n",
    "\n",
    "# Variance of σ̂_N\n",
    "variance_std_dev = (1 / (2 * sample_std_dev)) * variance_variance\n",
    "\n",
    "# Output results\n",
    "print(f\"Sample: {sample}\")\n",
    "print(f\"Sample mean: {sample_mean:.4f}\")\n",
    "print(f\"Sample variance (σ̂²_N): {sample_variance:.4f}\")\n",
    "print(f\"Bias of σ̂²_N: {bias_variance:.4f}\")\n",
    "print(f\"Variance of σ̂²_N: {variance_variance:.4f}\")\n",
    "print(f\"Sample standard deviation (σ̂_N): {sample_std_dev:.4f}\")\n",
    "print(f\"Bias of σ̂_N: {bias_std_dev:.4f}\")\n",
    "print(f\"Variance of σ̂_N: {variance_std_dev:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5651b89fdcb3d5c",
   "metadata": {},
   "source": [
    "---\n",
    "#### Task (b)\n",
    "The sample standard deviation $\\hat{\\sigma}_N$ can be written as a functional:\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}_N = T(F) = \\int (x - \\mu)^2 \\, dF(x)\n",
    "$$\n",
    "\n",
    "where $\\mu = \\int x \\, dF(x)$ is the population mean.\n",
    "\n",
    "When the distribution $F$ is perturbed by $\\delta y$, the mean becomes:\n",
    "\n",
    "$$\n",
    "\\mu_\\epsilon = (1 - \\epsilon) \\mu + \\epsilon y\n",
    "$$\n",
    "\n",
    "The variance changes to:\n",
    "\n",
    "$$\n",
    "\\sigma_\\epsilon^2 = \\int (x - \\mu_\\epsilon)^2 \\, dF_\\epsilon(x)\n",
    "$$\n",
    "\n",
    "Substitute $\\mu_\\epsilon$ into $\\sigma_\\epsilon^2$, keeping terms linear in $\\epsilon$:\n",
    "\n",
    "$$\n",
    "\\sigma_\\epsilon^2 = \\int (x - \\mu)^2 \\, dF(x) - 2\\epsilon (y - \\mu) \\int (x - \\mu) \\, dF(x) + \\epsilon (y - \\mu)^2\n",
    "$$\n",
    "\n",
    "Simplify using:\n",
    "\n",
    "$$\n",
    "\\int (x - \\mu) \\, dF(x) = 0\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "\\sigma_\\epsilon^2 = \\sigma^2 + \\epsilon (y - \\mu)^2\n",
    "$$\n",
    "\n",
    "The perturbed standard deviation becomes:\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}_N(F_\\epsilon) = \\sigma_\\epsilon^2\n",
    "$$\n",
    "\n",
    "Using a first-order Taylor expansion around $\\sigma^2$:\n",
    "\n",
    "$$\n",
    "\\hat{\\sigma}_N(F_\\epsilon) \\approx \\sigma + \\frac{1}{2} \\sigma \\epsilon (y - \\mu)^2\n",
    "$$\n",
    "\n",
    "The influence function is the derivative of $\\hat{\\sigma}_N$ with respect to $\\epsilon$:\n",
    "\n",
    "$$\n",
    "\\text{IF}(y; \\hat{\\sigma}_N, F) = \\frac{1}{2} \\sigma (y - \\mu)^2\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4fe187c1510bd4",
   "metadata": {},
   "source": [
    "### Problem 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f2ff24c49f4989",
   "metadata": {},
   "source": [
    "#### Task (a)\n",
    "For a significance level of $\\alpha = 0.01$:\n",
    "\n",
    "- The total rejection region must have probability $\\alpha = 0.01$.\n",
    "- Since the test is two-sided, the rejection region is split equally:\n",
    "  - $\\frac{\\alpha}{2} = 0.005$ in the left tail,\n",
    "  - $\\frac{\\alpha}{2} = 0.005$ in the right tail.\n",
    "\n",
    "Thus, the quantiles $q_1$ and $q_2$ correspond to:\n",
    "\n",
    "$$\n",
    "q_1 = 0.005, \\quad q_2 = 1 - 0.005 = 0.995\n",
    "$$\n",
    "\n",
    "The choice of $q_1 = 0.005$ and $q_2 = 0.995$ ensures the interval covers $1 - \\alpha = 99\\%$ of the bootstrap distribution under the null hypothesis. This aligns with the significance level $\\alpha = 0.01$, as 1% of the distribution lies outside the interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51797a74de521b4",
   "metadata": {},
   "source": [
    "---\n",
    "#### Task (b)\n",
    "For $q_1 = 0.005$ and $q_2 = 0.995$, the accuracy of the estimated quantiles depends on the number of bootstrap samples:\n",
    "\n",
    "$$\n",
    "\\text{Standard Error} = \\sqrt{\\frac{q(1 - q)}{B}}\n",
    "$$\n",
    "\n",
    "where $q$ is the quantile of interest (e.g., $q = 0.995$).\n",
    "\n",
    "For a reasonable precision (e.g., standard error $\\approx 0.001$):\n",
    "\n",
    "$$\n",
    "B \\geq \\frac{q(1 - q)}{(\\text{Standard Error})^2}\n",
    "$$\n",
    "\n",
    "For $q = 0.995$, $1 - q = 0.005$, and Standard Error = 0.001:\n",
    "\n",
    "$$\n",
    "B \\geq \\frac{0.995 \\times 0.005}{(0.001)^2} = 4975\n",
    "$$\n",
    "\n",
    "A common recommendation is:\n",
    "- $B \\geq 1000$ for rough estimates,\n",
    "- $B \\geq 5000$ for accurate quantile estimation.\n",
    "\n",
    "The choice of $B$ should balance accuracy with computational constraints. For modern computing systems, $B = 10,000$ is a practical and robust choice.\n",
    "\n",
    "Given the significance level $\\alpha = 0.01$ and the need to estimate extreme quantiles $q_1 = 0.005$ and $q_2 = 0.995$ with precision, I recommend:\n",
    "\n",
    "$$\n",
    "B = 10,000\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f943e4699ae9447",
   "metadata": {},
   "source": [
    "---\n",
    "#### Task (c)\n",
    "**Insights on the Procedure**\n",
    "- **Independence and Identical Distribution (i.i.d.)**: The bootstrap assumes that the data are independent and identically distributed.\n",
    "- **Nonparametric Approach**: The bootstrap works well when the underlying distribution is unknown or nonparametric.\n",
    "- **Significance Level Control**: The significance level $\\alpha = 0.01$ is controlled by choosing $q_1 = 0.005$ and $q_2 = 0.995$.\n",
    "- **Flexibility**: The bootstrap does not rely on parametric assumptions about the data distribution.\n",
    "- **Resampling**: By resampling directly from the data, the bootstrap captures the empirical variability of the sample.\n",
    "- **Quantile Estimation**: Direct computation of the rejection region using quantiles $q_1$ and $q_2$ ensures the desired confidence level.\n",
    "- **Small Sample Size**: If $N$ (sample size) is small, bootstrap samples may not sufficiently approximate the true distribution.\n",
    "- **Outliers**: Outliers in the original data can disproportionately affect bootstrap estimates.\n",
    "- **Computational Cost**: For large $B$, the method can become computationally expensive.\n",
    "\n",
    "\n",
    "**Proposed Improvements**\n",
    "\n",
    "- **Adjust for Small Sample Size**:\n",
    "  If the sample size $N$ is small, use **bias-corrected and accelerated (BCa) bootstrap**:\n",
    "  - Adjusts quantiles $q_1$ and $q_2$ to account for bias and skewness in the bootstrap distribution.\n",
    "\n",
    "- **Robustness to Outliers**:\n",
    "  Apply a robust statistic, such as the **trimmed mean** or **median**, instead of the sample mean $\\bar{Y}_N$. These measures are less sensitive to outliers.\n",
    "\n",
    "- **Precision in Quantile Estimation**:\n",
    "  Ensure $B$ is large enough (e.g., $B = 10,000$) to minimize variability in estimating $y(q_1)^*$ and $y(q_2)^*$.\n",
    "\n",
    "- **Alternative Resampling Methods**:\n",
    "  - **Wild Bootstrap**: Use when the data exhibit heteroscedasticity (unequal variance).\n",
    "  - **Block Bootstrap**: Use for dependent data to preserve the dependency structure.\n",
    "\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pnp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
